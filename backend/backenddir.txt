从数据库中读取pdf转换为document对象
text spllit
连接向量数据库，向量化处理

检索
构建更高效的检索，利用小模型预处理文本进行分块

为用户的query匹配指定的文档

结构化数据类型主要有三种：
1. xml
2. json
3. csv

将检索获得的文档插入到prompt中输入给大模型

搭建持久化存储，将用户对话记录存储到数据库中
搭建模型输出缓存，汇总功能

创建登陆页面，用户 ==》 会话  会话 ==》 招标书，应标书， 聊天记录

添加自动清理空白会话的功能

python manage.py makemigrations [应用名]

python manage.py makemigrations


                # 创建PromptGenerator实例
                prompt_generator = PromptGenerator()
                
                # 准备基础插槽数据
                slot_data = {
                    "topic": "招标审核",
                    "query": message,
                    "language": "中文"
                }
                
                # 生成包含文档搜索结果的提示（仅用于测试）
                prompt = prompt_generator.generate_prompt_with_search(
                    query=message,
                    slot_data=slot_data,
                    top_k=3
                )
                
                # 仅打印生成的prompt用于测试
                logger.info("[测试] 文档检索和Prompt生成结果:")
                logger.info("-"*30)
                logger.info(f"生成的完整prompt:\n{prompt}")
                logger.info("-"*30)
                
                # 使用普通对话模式
                response = llm.invoke(message)
                
                # 保存AI响应消息
                chat_session.messages.create(
                    content=response.content,
                    is_user=False
                )
                
                logger.info(f"LLM响应:\n{response.content}")
                logger.info("="*50)

将前端上传的文件区分为招标书和应标书 ✅
将rag作为一个工具，提供给控制者在需要的时候调用。
肯定不想要每次请求都调用rag，只在需要时调用

检查一下递归分割的代码，适当增加一下chunk size
阅读Agentic Chunking
优化一下loader
